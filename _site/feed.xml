<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jaeuk&apos;s Blog</title>
    <description>Data Science | ML/DL | Data engineering</description>
    <link>https://didwodnr123.github.io/</link>
    <atom:link href="https://didwodnr123.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 06 Jun 2021 17:07:54 +0900</pubDate>
    <lastBuildDate>Sun, 06 Jun 2021 17:07:54 +0900</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>[ML] 회귀</title>
        <description>&lt;h2 id=&quot;linear-regression&quot;&gt;Linear Regression&lt;/h2&gt;

&lt;p&gt;선형 회귀는 가장 대표적인 회귀 알고리즘이다. 상대적으로 간단하고 성능이 뛰어나다. 2차원 좌표상에 임의의 점들이 흩어져 있다고 상상했을때 그 점들을 가장 예쁘게 지나는 선을 긋는다고 생각하면 쉽다.&lt;/p&gt;

&lt;p&gt;흩어진 점들 간의 관계를 y = ax + b 식으로 풀어내면, 모든 점들을 가장 잘 만족시키는 a 와 b를 구할 수 있다. 여기서 a는 coefficient, b는 intercept 라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../img/in-post/linear_regression.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_regression&quot;&gt;source: wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Jun 2021 16:37:03 +0900</pubDate>
        <link>https://didwodnr123.github.io/regression.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/regression.html</guid>
        
        <category>ML</category>
        
        <category>Regression</category>
        
        
      </item>
    
      <item>
        <title>[Plan] 데이터 사이언스 공부 계획</title>
        <description>&lt;p&gt;2021년 데이터 사이언스를 공부하기 위한 학습 계획을 세워보려고 합니다. 몇 가지 유익한 Lecture를 적어놓고 순차적으로 이수 할 계획입니다.&lt;/p&gt;

&lt;p&gt;[혼자 공부하는 머신러닝+딥러닝] 책을 활용해서 머신러닝과 딥러닝에 대한 전반적인 기본기를 탄탄하게 다지고 가고 싶다.&lt;/p&gt;

&lt;h2 id=&quot;to-do&quot;&gt;To Do&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[MIT] 데이터 사이언스 기초 - &lt;a href=&quot;https://www.edwith.org/ds201/joinLectures/19265?isDesc=false&quot;&gt;edwith&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;[Harvard] 확률론 기초 - &lt;a href=&quot;https://www.edwith.org/ai152/joinLectures/17924?isDesc=false&quot;&gt;edwith&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;done&quot;&gt;Done&lt;/h2&gt;

&lt;h4 id=&quot;python&quot;&gt;Python&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모두를 위한 파이썬 : PY4E (Python for Everybody - Michigan univ. Charles Severance)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.edwith.org/pythonforeverybody&quot;&gt;edwith&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;모두를 위한 프로그래밍 : 파이썬
        &lt;ul&gt;
          &lt;li&gt;Getting Started with Python&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;파이썬 자료구조
        &lt;ul&gt;
          &lt;li&gt;Python Data Structures&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;파이썬을 이용한 웹 스크래핑
        &lt;ul&gt;
          &lt;li&gt;Using Python to Access Web Data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;파이썬을 이용한 데이터베이스 처리
        &lt;ul&gt;
          &lt;li&gt;Using Databased with Python&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;캡스톤 : 파이썬을 이용한 데이터 검색, 처리 및 시각화
        &lt;ul&gt;
          &lt;li&gt;Capstone : Retreiving, Processing and Visualizing Data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 06 Jun 2021 15:16:21 +0900</pubDate>
        <link>https://didwodnr123.github.io/plan.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/plan.html</guid>
        
        <category>Plan</category>
        
        
      </item>
    
      <item>
        <title>[독서] 유시민의 글쓰기 특강</title>
        <description>&lt;h2 id=&quot;유시민의-글쓰기-특강&quot;&gt;[유시민의 글쓰기 특강]&lt;/h2&gt;

&lt;p&gt;독서를 결심한 것은 이번이 처음이 아니다. 그 동안 책을 읽기로 결심하고 독서 노트를 구매하고, 만년필을 사는 등, 별 쓸 데 없는 것들을 많이 했다. 정작 중요한 독서는 뒷전이었다. 이번 계기를 통해 열심히 독서하고 열심히 글을 써보려고 한다.&lt;/p&gt;

&lt;p&gt;이 책을 읽게된 계기는 블로그를 시작하면서 어떻게 글을 써야할까에 대해 고민하다 생겨났다. 남들 다 하는 기술 블로그가 하고 싶어 이틀 밤낮을 꼬박 투자해서 Jekyll 과 github pages를 사용해서 블로그를 만들었는데 도저히 첫 줄을 쓸 수가 없었다. 무엇을 써야할지 고민하며 이런 저런 쓸 데 없는 짧은 문장이나 링크, 추천 강의 사이트를 두서없이 올렸다. 글을 포스팅 했을 당시에는 기분이 썩 좋았다. 내가 스스로 남들에게 도움이 될 만한 포스팅을 작성한 것 같은 기분이 들었다.&lt;/p&gt;

&lt;p&gt;며칠 뒤, 다시 블로그에 접속해서 글을 보니 한심하기 짝이 없었다. 두 세줄의 글과 대충 올려놓은 링크는 보는 사람으로 하여금 아무런 도움도 받지 못할 것 같은 글이었다. 이런 글 말고 나도 남들에게 진정으로 도움이 될 수 있는 글을 써보고 싶다는 생각이 들었다.&lt;/p&gt;

&lt;p&gt;나는 항상 무엇인가 제대로 하고 싶다는 생각이 들면 2가지 방법 중 택 1을 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;구글링을 해서 좋은 참고 자료를 찾는다.&lt;/li&gt;
  &lt;li&gt;책을 사서 본다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이번에는 2번째 방법을 택했다. “유시민의 글쓰기 특강” 은 책을 잘 읽지 않는 나도 알고 있는 책이었고 리뷰도 훌륭했기 때문에 책을 선택하고 곧장 읽기로 다짐했다. 유시민님의 책 중 “국가란 무엇인가” 를 읽은 적이 있는데, 이 책은 ‘국가란 무엇인가’ 와 비교해서 쉬운 어휘와 문장으로 구성되어 있다.&lt;/p&gt;

&lt;h2 id=&quot;발췌-요약에서-출발하자&quot;&gt;발췌 요약에서 출발하자&lt;/h2&gt;

&lt;p&gt;유시민님이 추천하시는 글쓰기의 출발점은 발췌 요약이다. 말 그대로 기사, 책 등의 글에서 중심 내용을 발췌 후 요약하는 방법이다. 이 방법을 사용해서 글쓰기를 시작해보자.&lt;/p&gt;

&lt;h4 id=&quot;글쓰기-철칙&quot;&gt;글쓰기 철칙&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;많이 읽어야 잘 쓴다.&lt;/li&gt;
  &lt;li&gt;많이 쓸수록 잘 쓴다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;발췌 요약을 하기 전, 알아두어야 할 철칙이 있다. 발췌 요약을 한 두번 한다고 갑자기 유시민 작가님처럼 글을 쓸 수 있는 것은 절대 아니다. 많이 읽어야한다. 작가님이 읽은 책이나 기사, 시 등의 모든 텍스트들을 합하면 나같은 일반인들이 짐작할 수 없을 정도로 많을 것이다.&lt;/p&gt;

&lt;p&gt;두 번째, 많이 쓸수록 잘 쓴다. 이 철칙은 나의 경험으로 공감할 수 있었다. 대외 활동이나 동아리 지원시 자기소개서를 몇 번 작성해 보았는데, 처음에는 무슨 말을 써야할지 감도 잡히지 않았지만 몇 개 쓰다보니 그 다음부턴 보다 수월하게 작성할 수 있었다.&lt;/p&gt;

&lt;h4 id=&quot;좋은-글이란&quot;&gt;좋은 글이란&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;무슨 이야기를 하는지, 주제가 분명&lt;/li&gt;
  &lt;li&gt;주제를 다루는 데 필요한 사실과 정보&lt;/li&gt;
  &lt;li&gt;사실과 정보의 관계&lt;/li&gt;
  &lt;li&gt;적절한 어휘/문장으로 표현&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;글의 첫 문장은 그냥 단문으로 내지르자. 그게 곧 주제의 요약이 되며 차근차근 글에서 풀어나가면 된다.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Thu, 03 Jun 2021 22:21:53 +0900</pubDate>
        <link>https://didwodnr123.github.io/how-to-write.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/how-to-write.html</guid>
        
        <category>Reading</category>
        
        
      </item>
    
      <item>
        <title>[Tutorial] Keras: Basic classification</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/tutorials/keras/classification&quot;&gt;튜토리얼 출처: TensorFlow&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;keras&quot;&gt;Keras&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;a high-level API to build and train models in TensorFlow.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__version__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Tue, 01 Jun 2021 21:59:56 +0900</pubDate>
        <link>https://didwodnr123.github.io/basic-classification.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/basic-classification.html</guid>
        
        <category>Tutorial</category>
        
        <category>Keras</category>
        
        
      </item>
    
      <item>
        <title>[Plan] How to live?</title>
        <description>&lt;p&gt;선택과 집중&lt;/p&gt;

&lt;p&gt;하나를 하면서 자꾸 다른 것을 떠올림..&lt;/p&gt;

&lt;p&gt;일정한 취침 시간과 기상 시간을 지키지 못함..&lt;/p&gt;

&lt;p&gt;아침에 잘 일어나지 못함..&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;책을 읽자! : 독서노트 작성해서 계속 기억을 리마인드 하자.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;하기로 한 것은 무조건 하자. 미루고 미루다 보면 결국 못한다. 하더라도 시간이 너무 지체된다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;나 자신과의 약속을 지키자. 내일 일정이 있어서 일찍 들어가야 하는 날은 스스로 절제하자. 절제를 너무 못한다..&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Thu, 03 Jun 2021 18:59:58 +0900</pubDate>
        <link>https://didwodnr123.github.io/How-to-live.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/How-to-live.html</guid>
        
        <category>Plan</category>
        
        
      </item>
    
      <item>
        <title>[번역] 캐글: 머신러닝 시작하기</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;본 내용은 Kaggle &lt;a href=&quot;https://www.kaggle.com/dansbecker/how-models-work&quot;&gt;Intro to Machine Learning&lt;/a&gt; 을 참고하여 구성하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;우연히 유튜브에서 흥미로운 사람을 발견했습니다. Ken Jee 라는 유튜버인데, 데이터 사이언스에 관해 다양한 주제들로 영상을 제작하는 크리에이터 입니다. 이 분 영상 중  “&lt;a href=&quot;https://www.youtube.com/watch?v=4OZip0cgOho&quot;&gt;How I Would Learn Data Science (If I Had to Start Over)&lt;/a&gt;” 을 보면 데이터 사이언티스트를 준비하시는 분들에게 꽤나 도움이 될 것 같습니다. 다른 좋은 영상들도 많이 있으니 참고해보세요! Ken이 추천한 학습 방법 중 하나가 바로 제가 포스팅 할 &lt;strong&gt;Kaggle micro-course&lt;/strong&gt; 입니다. Python부터 SQL, ML, DL 까지 상세하게 정리되어 있고, 무엇보다 실습이 있다는 것이 가장 큰 장점입니다.&lt;/p&gt;

&lt;h2 id=&quot;how-models-work&quot;&gt;How Models Work&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/7tsb5b1.png&quot; alt=&quot;First Decision Trees&quot; /&gt;&lt;/p&gt;

&lt;p&gt;간단한 Decision Tree 모양입니다.&lt;/p&gt;

&lt;p&gt;이 Decision Tree는 오직 2개의 카테고리로 집들을 분류합니다. 예측된 가격은 같은 카테고리에 있는 집들의 평균 가격 정도로 이해하시면 됩니다.&lt;/p&gt;

&lt;p&gt;사람들은 어떻게 집들을 두 개의 카테고리로 나눌 지 데이터를 사용해서 결정한 후, 각 그룹의 예측 가격을 결정합니다. 데이터로부터 이 패턴을 구성하는 단계를 &lt;strong&gt;Fitting&lt;/strong&gt; or &lt;strong&gt;Training&lt;/strong&gt; the model 이라 합니다. Model을 Fitting 시키는 데 사용되는 데이터를 &lt;strong&gt;training data&lt;/strong&gt;라 합니다.&lt;/p&gt;

&lt;p&gt;어떻게 모델이 Fitting 되는 지에 대한 내용은 꽤 복잡하기 때문에 나중에 심화 과정에서 배워도 됩니다. 모델이 한 번 Fitting 되고 나면 새로운 데이터를 사용해서 추가적으로 집 값을 예측할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;improving-the-decision-tree&quot;&gt;Improving the Decision Tree&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/prAjgku.png&quot; alt=&quot;First Decision Trees&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 방이 2개 이상인 집이 더 비쌉니다. 따라서 왼쪽 Tree가 더 논리적으로 맞다는 것을 확인할 수 있습니다. 하지만 이것의 가장 큰 단점은 집들의 다양한 특징들을 고려하지 못한다는 것입니다…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/R3ywQsR.png&quot; alt=&quot;Depth 2 Tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 tree를 보다 &lt;strong&gt;Deep&lt;/strong&gt; 하게 구성해야 합니다. 이것도 사실은 부족하지만 이해를 돕기에는 충분하다고 생각합니다. 마지막으로 맨 끝에 위치한 박스? 를 &lt;strong&gt;Leaf&lt;/strong&gt;라고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;basic-data-exploration&quot;&gt;Basic Data Exploration&lt;/h2&gt;

&lt;h4 id=&quot;using-pandas-to-get-familiar-with-your-data&quot;&gt;Using Pandas to Get Familiar With Your Data&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;판다스 라이브러리 중 가장 중요한 것은 DataFrame 입니다. 데이터프레임은 데이터를 엑셀 표 처럼 구성해주는 역할을 합니다. 지금부터 Melbourne, Australia의 집값 데이터를 활용해서 pandas를 사용해보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# save filepath to variable for easier access
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_file_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;./data/melb_data.csv&apos;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read the data and store data in DataFrame titled melbourne_data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# print a summary of the data in Melbourne data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;describe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 31 May 2021 00:00:00 +0900</pubDate>
        <link>https://didwodnr123.github.io/intro-to-ML.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/intro-to-ML.html</guid>
        
        <category>Translation</category>
        
        <category>Kaggle</category>
        
        
      </item>
    
      <item>
        <title>[AI study] Week1: Intro to GAN</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;본 내용은 Coursera &lt;a href=&quot;https://www.coursera.org/programs/96b56ed6-2c7a-4373-92df-2d467731559d/browse?currentTab=CATALOG&amp;amp;productId=I7xTyNLAEeqdUQo9B2YGiw&amp;amp;productType=s12n&amp;amp;query=GAN&amp;amp;showMiniModal=true&quot;&gt;Build Basic Generative Adversarial Networks (GANs)&lt;/a&gt; Lecture 기반으로 구성했습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;지난주, Coursera Andrew Ng 교수님의 Deep learning specialization을 마무리했습니다. 이번주부터는 굉장히 섬세한 fake 이미지를 생성할 수 있는 GAN 모델을 다루는 강의를 시청하고 리뷰할 예정입니다.&lt;/p&gt;

&lt;p&gt;GAN 이란 Generative Adverarial Network의 약자로, 하나의 모델이 가짜 이미지를 생성하고 다른 모델이 진짜 이미지와 가짜 이미지를 구분? 하면서 Generator 모델이 더욱 완벽한 fake 이미지를 만들 수 있도록 training 합니다.&lt;/p&gt;

&lt;h2 id=&quot;generative-models&quot;&gt;Generative Models&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/AI_study/gan1.png&quot; alt=&quot;GAN&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Generator&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Random noise를 input에 주고 fake image를 생성합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Discriminator&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Real image를 input에 주고 학습시킵니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;학습이 완료되면 Random Noise를 input으로 Generator에 주게 되면 정교한 fake 이미지를 생성하게 됩니다. 그리고 위 모델들이 경쟁하며 성능을 향상시키는 구조를 갖고 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;summary&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Generative models learn to produce &lt;strong&gt;realistic&lt;/strong&gt; examples&lt;/li&gt;
  &lt;li&gt;Discriminative models distinguish between classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;real-life-gans&quot;&gt;Real Life GANs&lt;/h2&gt;

&lt;p&gt;Ian Goodfellow is known as the creator of the GAN.&lt;/p&gt;

&lt;p&gt;not limited to human faces&lt;/p&gt;

&lt;p&gt;image translation : horse to zebra, vice versa&lt;/p&gt;

&lt;p&gt;draw something -&amp;gt; able to produce realistic image&lt;/p&gt;

&lt;p&gt;Monariza -&amp;gt; moving&lt;/p&gt;

&lt;p&gt;Companies Using GANs&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Adobe&lt;/li&gt;
  &lt;li&gt;Google (text generation)&lt;/li&gt;
  &lt;li&gt;IBM (data augmentation) : x enough data -&amp;gt; augmentation&lt;/li&gt;
  &lt;li&gt;whatever you like&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-1&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;GANs’ performance is rapidly improving&lt;/li&gt;
  &lt;li&gt;Huge opportunity to work in this space!&lt;/li&gt;
  &lt;li&gt;Major companies are using them&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intuition-behind-gans&quot;&gt;Intuition Behind GANs&lt;/h2&gt;

&lt;h4 id=&quot;outline&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;the goal of the generator and the discriminator&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;the competition between them&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Generator : learn to make fakes that look real&lt;/p&gt;

&lt;p&gt;Discriminator : learns to distinguish real from fake&lt;/p&gt;

&lt;p&gt;First, train a discriminator&lt;/p&gt;

&lt;h4 id=&quot;summary-2&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;generator’s&lt;/strong&gt; goal is to fool the discriminator&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;discriminator’s&lt;/strong&gt; goal is to distinguish between real and fake&lt;/li&gt;
  &lt;li&gt;They learn from the competition with each other&lt;/li&gt;
  &lt;li&gt;At the end, &lt;strong&gt;fakes&lt;/strong&gt; look &lt;strong&gt;real&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;discriminator&quot;&gt;Discriminator&lt;/h2&gt;

&lt;h4 id=&quot;outline-1&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Review of classifiers&lt;/li&gt;
  &lt;li&gt;The role of classifiers in terms of probability&lt;/li&gt;
  &lt;li&gt;Discriminator&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Discriminator : Distinguish between different classes&lt;/p&gt;

&lt;h4 id=&quot;summary-3&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;discriminator&lt;/strong&gt; is a classifier&lt;/li&gt;
  &lt;li&gt;It learns the probability of class Y (&lt;strong&gt;real&lt;/strong&gt; or &lt;strong&gt;fake&lt;/strong&gt;) given features X&lt;/li&gt;
  &lt;li&gt;The probabilities are the feedback for the &lt;strong&gt;generator&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generator&quot;&gt;Generator&lt;/h2&gt;

&lt;h4 id=&quot;outline-2&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;What the generator does&lt;/li&gt;
  &lt;li&gt;How it improves its performance&lt;/li&gt;
  &lt;li&gt;Generator in terms of probability&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Noise vector - different output&lt;/p&gt;

&lt;p&gt;Noise -&amp;gt; &lt;strong&gt;Generator&lt;/strong&gt; -&amp;gt; Features(X hat) -&amp;gt; **Discriminator ** -&amp;gt; Output (Y hat) -&amp;gt; Cost -&amp;gt; update Generator’s Parameters&lt;/p&gt;

&lt;h4 id=&quot;summary-4&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;Generator&lt;/strong&gt; produces fake data&lt;/li&gt;
  &lt;li&gt;It learns the probability of features X&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;Generator&lt;/strong&gt; takes as input noise (random features)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bce-cost-function&quot;&gt;BCE Cost Function&lt;/h2&gt;

&lt;h4 id=&quot;outline-3&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Binary Cross Entropy(BCE) Loss equation by parts&lt;/li&gt;
  &lt;li&gt;How it looks graphically&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-5&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The BCE cost function has two parts (one relevant for each class)&lt;/li&gt;
  &lt;li&gt;Close to zero when label and the prediction are similar&lt;/li&gt;
  &lt;li&gt;Approaches infinity when the label and the prediction are different&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;

&lt;h4 id=&quot;outline-4&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;How the whole architecture looks&lt;/li&gt;
  &lt;li&gt;How to train GANs&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-6&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;GANs train in an alternating fashion&lt;/li&gt;
  &lt;li&gt;The two models should always be at a similar “skill” level&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intro-to-pytorch&quot;&gt;Intro to PyTorch&lt;/h2&gt;

&lt;h4 id=&quot;outline-5&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Comparison with TensorFlow&lt;/li&gt;
  &lt;li&gt;Dfining Models&lt;/li&gt;
  &lt;li&gt;Training&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/AI_study/pytorch_vs_tensorflow.png&quot; alt=&quot;GAN&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/didwodnr123/didwodnr123.github.io/blob/main/img/AI_study/5.PNG?raw=true&quot; alt=&quot;GAN1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/didwodnr123/didwodnr123.github.io/blob/main/img/AI_study/6.PNG?raw=true&quot; alt=&quot;GAN2&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;summary-7&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;PyTorch makes computations on the run&lt;/li&gt;
  &lt;li&gt;Dynamic computational graphs in PyTorch&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Just another framework, and similar to Tensorflow!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 27 May 2021 00:00:00 +0900</pubDate>
        <link>https://didwodnr123.github.io/week1.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/week1.html</guid>
        
        <category>AI Study</category>
        
        <category>GAN</category>
        
        
      </item>
    
  </channel>
</rss>
