<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jaeuk&apos;s Blog</title>
    <description>Data Science | ML/DL | Data engineering</description>
    <link>https://didwodnr123.github.io/</link>
    <atom:link href="https://didwodnr123.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 02 Jun 2021 00:38:23 +0900</pubDate>
    <lastBuildDate>Wed, 02 Jun 2021 00:38:23 +0900</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title></title>
        <description>&lt;h2 id=&quot;유시민의-글쓰기-특강&quot;&gt;[유시민의 글쓰기 특강]&lt;/h2&gt;

</description>
        <pubDate>Wed, 02 Jun 2021 00:38:01 +0900</pubDate>
        <link>https://didwodnr123.github.io/how-to-write.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/how-to-write.html</guid>
        
        
      </item>
    
      <item>
        <title>[Tutorial] Keras: Basic classification</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/tutorials/keras/classification&quot;&gt;튜토리얼 출처: TensorFlow&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;keras&quot;&gt;Keras&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;a high-level API to build and train models in TensorFlow.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__version__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Tue, 01 Jun 2021 21:59:56 +0900</pubDate>
        <link>https://didwodnr123.github.io/basic-classification.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/basic-classification.html</guid>
        
        <category>Tutorial</category>
        
        <category>Keras</category>
        
        
      </item>
    
      <item>
        <title>[번역] Intro to Machine Learning</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;본 내용은 Kaggle &lt;a href=&quot;https://www.kaggle.com/dansbecker/how-models-work&quot;&gt;Intro to Machine Learning&lt;/a&gt; 을 참고하여 구성하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;우연히 유튜브에서 흥미로운 사람을 발견했습니다. Ken Jee 라는 유튜버인데, 데이터 사이언스에 관해 다양한 주제들로 영상을 제작하는 크리에이터 입니다. 이 분 영상 중  “&lt;a href=&quot;https://www.youtube.com/watch?v=4OZip0cgOho&quot;&gt;How I Would Learn Data Science (If I Had to Start Over)&lt;/a&gt;” 을 보면 데이터 사이언티스트를 준비하시는 분들에게 꽤나 도움이 될 것 같습니다. 다른 좋은 영상들도 많이 있으니 참고해보세요! Ken이 추천한 학습 방법 중 하나가 바로 제가 포스팅 할 &lt;strong&gt;Kaggle micro-course&lt;/strong&gt; 입니다. Python부터 SQL, ML, DL 까지 상세하게 정리되어 있고, 무엇보다 실습이 있다는 것이 가장 큰 장점입니다.&lt;/p&gt;

&lt;h2 id=&quot;how-models-work&quot;&gt;How Models Work&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/7tsb5b1.png&quot; alt=&quot;First Decision Trees&quot; /&gt;&lt;/p&gt;

&lt;p&gt;간단한 Decision Tree 모양입니다.&lt;/p&gt;

&lt;p&gt;이 Decision Tree는 오직 2개의 카테고리로 집들을 분류합니다. 예측된 가격은 같은 카테고리에 있는 집들의 평균 가격 정도로 이해하시면 됩니다.&lt;/p&gt;

&lt;p&gt;사람들은 어떻게 집들을 두 개의 카테고리로 나눌 지 데이터를 사용해서 결정한 후, 각 그룹의 예측 가격을 결정합니다. 데이터로부터 이 패턴을 구성하는 단계를 &lt;strong&gt;Fitting&lt;/strong&gt; or &lt;strong&gt;Training&lt;/strong&gt; the model 이라 합니다. Model을 Fitting 시키는 데 사용되는 데이터를 &lt;strong&gt;training data&lt;/strong&gt;라 합니다.&lt;/p&gt;

&lt;p&gt;어떻게 모델이 Fitting 되는 지에 대한 내용은 꽤 복잡하기 때문에 나중에 심화 과정에서 배워도 됩니다. 모델이 한 번 Fitting 되고 나면 새로운 데이터를 사용해서 추가적으로 집 값을 예측할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;improving-the-decision-tree&quot;&gt;Improving the Decision Tree&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/prAjgku.png&quot; alt=&quot;First Decision Trees&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 방이 2개 이상인 집이 더 비쌉니다. 따라서 왼쪽 Tree가 더 논리적으로 맞다는 것을 확인할 수 있습니다. 하지만 이것의 가장 큰 단점은 집들의 다양한 특징들을 고려하지 못한다는 것입니다…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/R3ywQsR.png&quot; alt=&quot;Depth 2 Tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 tree를 보다 &lt;strong&gt;Deep&lt;/strong&gt; 하게 구성해야 합니다. 이것도 사실은 부족하지만 이해를 돕기에는 충분하다고 생각합니다. 마지막으로 맨 끝에 위치한 박스? 를 &lt;strong&gt;Leaf&lt;/strong&gt;라고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;basic-data-exploration&quot;&gt;Basic Data Exploration&lt;/h2&gt;

&lt;h4 id=&quot;using-pandas-to-get-familiar-with-your-data&quot;&gt;Using Pandas to Get Familiar With Your Data&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;판다스 라이브러리 중 가장 중요한 것은 DataFrame 입니다. 데이터프레임은 데이터를 엑셀 표 처럼 구성해주는 역할을 합니다. 지금부터 Melbourne, Australia의 집값 데이터를 활용해서 pandas를 사용해보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# save filepath to variable for easier access
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_file_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;./data/melb_data.csv&apos;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read the data and store data in DataFrame titled melbourne_data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# print a summary of the data in Melbourne data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;melbourne_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;describe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 31 May 2021 00:00:00 +0900</pubDate>
        <link>https://didwodnr123.github.io/intro-to-ML.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/intro-to-ML.html</guid>
        
        <category>Translation</category>
        
        <category>Kaggle</category>
        
        
      </item>
    
      <item>
        <title>[AI study] Week1: Intro to GAN</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;본 내용은 Coursera &lt;a href=&quot;https://www.coursera.org/programs/96b56ed6-2c7a-4373-92df-2d467731559d/browse?currentTab=CATALOG&amp;amp;productId=I7xTyNLAEeqdUQo9B2YGiw&amp;amp;productType=s12n&amp;amp;query=GAN&amp;amp;showMiniModal=true&quot;&gt;Build Basic Generative Adversarial Networks (GANs)&lt;/a&gt; Lecture 기반으로 구성했습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;지난주, Coursera Andrew Ng 교수님의 Deep learning specialization을 마무리했습니다. 이번주부터는 굉장히 섬세한 fake 이미지를 생성할 수 있는 GAN 모델을 다루는 강의를 시청하고 리뷰할 예정입니다.&lt;/p&gt;

&lt;p&gt;GAN 이란 Generative Adverarial Network의 약자로, 하나의 모델이 가짜 이미지를 생성하고 다른 모델이 진짜 이미지와 가짜 이미지를 구분? 하면서 Generator 모델이 더욱 완벽한 fake 이미지를 만들 수 있도록 training 합니다.&lt;/p&gt;

&lt;h2 id=&quot;generative-models&quot;&gt;Generative Models&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/AI_study/gan1.png&quot; alt=&quot;GAN&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Generator&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Random noise를 input에 주고 fake image를 생성합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Discriminator&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Real image를 input에 주고 학습시킵니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;학습이 완료되면 Random Noise를 input으로 Generator에 주게 되면 정교한 fake 이미지를 생성하게 됩니다. 그리고 위 모델들이 경쟁하며 성능을 향상시키는 구조를 갖고 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;summary&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Generative models learn to produce &lt;strong&gt;realistic&lt;/strong&gt; examples&lt;/li&gt;
  &lt;li&gt;Discriminative models distinguish between classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;real-life-gans&quot;&gt;Real Life GANs&lt;/h2&gt;

&lt;p&gt;Ian Goodfellow is known as the creator of the GAN.&lt;/p&gt;

&lt;p&gt;not limited to human faces&lt;/p&gt;

&lt;p&gt;image translation : horse to zebra, vice versa&lt;/p&gt;

&lt;p&gt;draw something -&amp;gt; able to produce realistic image&lt;/p&gt;

&lt;p&gt;Monariza -&amp;gt; moving&lt;/p&gt;

&lt;p&gt;Companies Using GANs&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Adobe&lt;/li&gt;
  &lt;li&gt;Google (text generation)&lt;/li&gt;
  &lt;li&gt;IBM (data augmentation) : x enough data -&amp;gt; augmentation&lt;/li&gt;
  &lt;li&gt;whatever you like&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-1&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;GANs’ performance is rapidly improving&lt;/li&gt;
  &lt;li&gt;Huge opportunity to work in this space!&lt;/li&gt;
  &lt;li&gt;Major companies are using them&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intuition-behind-gans&quot;&gt;Intuition Behind GANs&lt;/h2&gt;

&lt;h4 id=&quot;outline&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;the goal of the generator and the discriminator&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;the competition between them&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Generator : learn to make fakes that look real&lt;/p&gt;

&lt;p&gt;Discriminator : learns to distinguish real from fake&lt;/p&gt;

&lt;p&gt;First, train a discriminator&lt;/p&gt;

&lt;h4 id=&quot;summary-2&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;generator’s&lt;/strong&gt; goal is to fool the discriminator&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;discriminator’s&lt;/strong&gt; goal is to distinguish between real and fake&lt;/li&gt;
  &lt;li&gt;They learn from the competition with each other&lt;/li&gt;
  &lt;li&gt;At the end, &lt;strong&gt;fakes&lt;/strong&gt; look &lt;strong&gt;real&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;discriminator&quot;&gt;Discriminator&lt;/h2&gt;

&lt;h4 id=&quot;outline-1&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Review of classifiers&lt;/li&gt;
  &lt;li&gt;The role of classifiers in terms of probability&lt;/li&gt;
  &lt;li&gt;Discriminator&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Discriminator : Distinguish between different classes&lt;/p&gt;

&lt;h4 id=&quot;summary-3&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;discriminator&lt;/strong&gt; is a classifier&lt;/li&gt;
  &lt;li&gt;It learns the probability of class Y (&lt;strong&gt;real&lt;/strong&gt; or &lt;strong&gt;fake&lt;/strong&gt;) given features X&lt;/li&gt;
  &lt;li&gt;The probabilities are the feedback for the &lt;strong&gt;generator&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generator&quot;&gt;Generator&lt;/h2&gt;

&lt;h4 id=&quot;outline-2&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;What the generator does&lt;/li&gt;
  &lt;li&gt;How it improves its performance&lt;/li&gt;
  &lt;li&gt;Generator in terms of probability&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Noise vector - different output&lt;/p&gt;

&lt;p&gt;Noise -&amp;gt; &lt;strong&gt;Generator&lt;/strong&gt; -&amp;gt; Features(X hat) -&amp;gt; **Discriminator ** -&amp;gt; Output (Y hat) -&amp;gt; Cost -&amp;gt; update Generator’s Parameters&lt;/p&gt;

&lt;h4 id=&quot;summary-4&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;Generator&lt;/strong&gt; produces fake data&lt;/li&gt;
  &lt;li&gt;It learns the probability of features X&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;Generator&lt;/strong&gt; takes as input noise (random features)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bce-cost-function&quot;&gt;BCE Cost Function&lt;/h2&gt;

&lt;h4 id=&quot;outline-3&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Binary Cross Entropy(BCE) Loss equation by parts&lt;/li&gt;
  &lt;li&gt;How it looks graphically&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-5&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The BCE cost function has two parts (one relevant for each class)&lt;/li&gt;
  &lt;li&gt;Close to zero when label and the prediction are similar&lt;/li&gt;
  &lt;li&gt;Approaches infinity when the label and the prediction are different&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;

&lt;h4 id=&quot;outline-4&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;How the whole architecture looks&lt;/li&gt;
  &lt;li&gt;How to train GANs&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-6&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;GANs train in an alternating fashion&lt;/li&gt;
  &lt;li&gt;The two models should always be at a similar “skill” level&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intro-to-pytorch&quot;&gt;Intro to PyTorch&lt;/h2&gt;

&lt;h4 id=&quot;outline-5&quot;&gt;Outline&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Comparison with TensorFlow&lt;/li&gt;
  &lt;li&gt;Dfining Models&lt;/li&gt;
  &lt;li&gt;Training&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/AI_study/pytorch_vs_tensorflow.png&quot; alt=&quot;GAN&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/didwodnr123/didwodnr123.github.io/blob/main/img/AI_study/5.PNG?raw=true&quot; alt=&quot;GAN1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/didwodnr123/didwodnr123.github.io/blob/main/img/AI_study/6.PNG?raw=true&quot; alt=&quot;GAN2&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;summary-7&quot;&gt;Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;PyTorch makes computations on the run&lt;/li&gt;
  &lt;li&gt;Dynamic computational graphs in PyTorch&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Just another framework, and similar to Tensorflow!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 27 May 2021 00:00:00 +0900</pubDate>
        <link>https://didwodnr123.github.io/week1.html</link>
        <guid isPermaLink="true">https://didwodnr123.github.io/week1.html</guid>
        
        <category>AI Study</category>
        
        <category>GAN</category>
        
        
      </item>
    
  </channel>
</rss>
